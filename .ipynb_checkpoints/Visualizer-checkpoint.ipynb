{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "tf.__version__\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "\n",
    "LOG_DIR = PATH+ '/embedding-logs'\n",
    "#metadata = os.path.join(LOG_DIR, 'metadata2.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-texas\n",
      "\n",
      "Loaded the images of dataset-stop\n",
      "\n",
      "Loaded the images of dataset-streetlight\n",
      "\n",
      "Loaded the images of dataset-exit\n",
      "\n",
      "Loaded the images of dataset-warning\n",
      "\n",
      "Loaded the images of dataset-speed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "data_path = PATH + '/data'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_data=[]\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img_resize=cv2.resize(input_img,(150,150))\n",
    "        img_data.append(input_img_resize)\n",
    "    \n",
    "                \n",
    "img_data = np.array(img_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('feature_vectors_shape:', (235, 279))\n",
      "('num of images:', 235)\n",
      "('size of individual feature vector:', 279)\n",
      "235\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "feature_vectors = np.loadtxt('feature_vectors.txt')\n",
    "print (\"feature_vectors_shape:\",feature_vectors.shape)\n",
    "print (\"num of images:\",feature_vectors.shape[0])\n",
    "print (\"size of individual feature vector:\",feature_vectors.shape[1])\n",
    "\n",
    "num_of_samples=feature_vectors.shape[0]\n",
    "print(num_of_samples)\n",
    "#num_of_samples_each_clasis = 100\n",
    "\n",
    "features = tf.Variable(feature_vectors, name='features')\n",
    "\n",
    "\n",
    "y = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "y[0:32]=0      #texas 32\n",
    "y[32:42]=1     #stop  10\n",
    "y[42:60]=2     #streetlight 18\n",
    "y[60:89]=3      #exit 29\n",
    "y[89:210]=4      #warning 121\n",
    "y[210:235]=5      #speed 25\n",
    "\n",
    "print y\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['texas','stop','streetlight','exit','warning','speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open(metadata, 'w') as metadata_file:\n",
    "#    for row in range(210):\n",
    "#        c = y[row]\n",
    "#        metadata_file.write('{}\\n'.format(c))\n",
    "metadata_file = open(os.path.join(LOG_DIR, 'metadata_6_classes.tsv'), 'w')\n",
    "metadata_file.write('Class\\tName\\n')\n",
    "k= 100# num of samples in each class\n",
    "j=0\n",
    "#for i in range(210):\n",
    "#    metadata_file.write('%06d\\t%s\\n' % (i, names[y[i]]))\n",
    "for i in range(num_of_samples):\n",
    "    c = names[y[i]]\n",
    "    #print(y[i], c)\n",
    "    metadata_file.write('{}\\t{}\\n'.format(y[i],c))\n",
    "    #metadata_file.write('%06d\\t%s\\n' % (j, c))\n",
    "metadata_file.close()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taken from: https://github.com/tensorflow/tensorflow/issues/6322\n",
    "def images_to_sprite(data):\n",
    "    \"\"\"Creates the sprite image along with any necessary padding\n",
    "\n",
    "    Args:\n",
    "      data: NxHxW[x3] tensor containing the images.\n",
    "\n",
    "    Returns:\n",
    "      data: Properly shaped HxWx3 image with any necessary padding.\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "    data = data.astype(np.float32)\n",
    "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n",
    "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n",
    "    # Inverting the colors seems to look better for MNIST\n",
    "    #data = 1 - data\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "            (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "            constant_values=0)\n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "            + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data\n",
    "#%%\n",
    "sprite = images_to_sprite(img_data)\n",
    "cv2.imwrite(os.path.join(LOG_DIR, 'sprite_6_classes.png'), sprite)\n",
    "#scipy.misc.imsave(os.path.join(LOG_DIR, 'sprite.png'), sprite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "sprite = images_to_sprite(img_data)\n",
    "cv2.imwrite(os.path.join(LOG_DIR, 'sprite_6_classes.png'), sprite)\n",
    "#scipy.misc.imsave(os.path.join(LOG_DIR, 'sprite.png'), sprite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver([features])\n",
    "\n",
    "    sess.run(features.initializer)\n",
    "    saver.save(sess, os.path.join(LOG_DIR, 'images_6_classes.ckpt'))\n",
    "    \n",
    "    config = projector.ProjectorConfig()\n",
    "    # One can add multiple embeddings.\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = features.name\n",
    "    # Link this tensor to its metadata file (e.g. labels).\n",
    "    embedding.metadata_path = os.path.join(LOG_DIR, 'metadata_6_classes.tsv')\n",
    "    # Comment out if you don't want sprites\n",
    "    embedding.sprite.image_path = os.path.join(LOG_DIR, 'sprite_6_classes.png')\n",
    "    embedding.sprite.single_image_dim.extend([img_data.shape[1], img_data.shape[1]])\n",
    "    # Saves a config file that TensorBoard will read during startup.\n",
    "    projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
